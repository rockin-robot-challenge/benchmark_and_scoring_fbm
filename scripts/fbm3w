#!/usr/bin/env python
import math
from math import sqrt, sin, cos, pi, atan2
import random
import time
import yaml

# ROS imports
import rospy
import tf
from rockin_scoring.BmBox import BmBox
from std_msgs.msg import Header
from geometry_msgs.msg import Pose2D, Pose, PoseStamped
from nav_msgs.msg import Path

# Benchmark runs
BENCHMARK_RUNS = 5

# c times mean distance measurement error
D_MIN = 0.00033 # reasonable with a smoothing value of 15

# robot path
robot_path = []



# target paths
def line_path(l):
	l = float(l)
	return Pose2D(0.15*l, 0.045*l, 0) # line from (0, 0) to (30, 10) [cm]

def semi_ellipse(l):
	l = float(l)
	return Pose2D(0.11 - 0.11*cos(pi*l), 0.11*sin(pi*l), 0) # semi ellipse (0,0),(5, 4.8), (10, 0) [cm]
	
def sine(l):
	l = float(l)
	return Pose2D(0.15*l, 0.075*sin(12.5*pi*0.15*l), 0) # semi ellipse (0,0),(5, 4.8), (10, 0) [cm]
	
	

spline_path = sine

tf_listener = None
tf_broadcaster = None

### Euclidean distance between Pose2D (p1, p2)
def d(p1, p2):
	return sqrt( (p1.x-p2.x)**2 + (p1.y-p2.y)**2 )

### Look for the robot from GT system
def acquire_robot_position():
	global tf_listener
	
	while True:
		try:
			((x, y, _), q) = tf_listener.lookupTransform("/world", "/robot_at_work", rospy.Time(0))
			(_, _, theta) = tf.transformations.euler_from_quaternion(q)
			
			return Pose2D(x, y, theta)
			
		except (tf.LookupException, tf.ConnectivityException, tf.ExtrapolationException, tf.Exception), Argument:
			rospy.loginfo("Position couldn't be acquired, retrying...")
			rospy.loginfo(Argument)
		#	tf_listener.waitForTransform("/world", "/robot_at_work", rospy.Time(), rospy.Duration(2.0))

### given a robot Pose2D relative to world, returns a Pose2D relative to robot_frame
def translate_robot_pose(robot_pose2D):
	global tf_listener, tf_broadcaster, robot_starting_position, ref_to_start_quaternion
	while True:
		try:
			now = rospy.Time.now()
			
			# broadcast robot_frame
			tf_broadcaster.sendTransform((robot_starting_position.x, robot_starting_position.y, 0), ref_to_start_quaternion, now, "/robot_frame", "/world")
			
			# broadcast robot position and lookup robot position in robot_frame
			tf_broadcaster.sendTransform( (robot_pose2D.x, robot_pose2D.y, 0.0), (0,0,0,1), now, "/robot_in_frame", "/world")
			
			tf_listener.waitForTransform("/robot_frame", "/robot_in_frame", now, rospy.Duration(2.0) )
			((x, y, _), _) = tf_listener.lookupTransform("/robot_frame", "/robot_in_frame", now) # to obtain robot wrt path
			
			return Pose2D(x, y, 0)
		
		except (tf.LookupException, tf.ConnectivityException, tf.ExtrapolationException, tf.Exception), Argument:
			rospy.loginfo("Transform couldn't be computed, retrying...")
			# return None

def pose2D_to_pose(pose2D):
	ps = PoseStamped()
	p = Pose()
	p.position.x = pose2D.x
	p.position.y = pose2D.y
	ps.pose = p
	return ps

def broadcast_pose2D(pose2D, timestamp, child, parent):
	tf_broadcaster.sendTransform( (pose2D.x, pose2D.y, 0.0), (0,0,0,1), timestamp, child, parent)




###############################
####  benchmark functions  ####
###############################

### Acquire reference_position
def acquire_reference_position():
	global robot_reference_position
	
	robot_reference_position = acquire_robot_position()
	rospy.loginfo("Acquired reference_position\n%s", robot_reference_position)

### Acquire starting_position
def acquire_starting_position():
	global robot_starting_position
	
	robot_starting_position = acquire_robot_position()
	rospy.loginfo("Acquired starting_position\n%s", robot_starting_position)

### Acquire starting_position from robot_path (the first position in robot's path
def acquire_starting_position_from_path():
	global robot_starting_position, robot_path
	
	print robot_path
	robot_starting_position = robot_path[0]
	rospy.loginfo("Acquired starting_position from robot_path\n%s", robot_starting_position)

### Updates ref_to_start_quaternion, so that robot_frame will be rotated as robot_starting_position - robot_reference_position
def update_robot_frame():
	global robot_reference_position, robot_starting_position, ref_to_start_quaternion
	
	ref_to_start_vector = (robot_starting_position.y - robot_reference_position.y, robot_starting_position.x - robot_reference_position.x)
	ref_to_start_quaternion = tf.transformations.quaternion_from_euler(0, 0, atan2(*ref_to_start_vector))
	
	print "robot_frame theta: ", atan2(*ref_to_start_vector)/pi*180


### Start collecting robot positions
def start_collecting_robot_path():
	global robot_path, mocap_subscriber
	
	robot_path = []
	mocap_subscriber = rospy.Subscriber("/fbm3w/robot_at_work/pose2d", Pose2D, mocap_callback)
	rospy.loginfo('Subscribed to "/fbm3w/robot_at_work/pose2d"')

### End collecting robot positions
def end_collecting_robot_path():
	global mocap_subscriber
	
	mocap_subscriber.unregister()
	rospy.loginfo('UNsubscribed from "/fbm3w/robot_at_work/pose2d"')

# note: untracked path is ignored and will be evaluated as a step
def mocap_callback(pose):
	global robot_path
	
	if len(robot_path)>0:
		if d(robot_path[-1], pose) >= D_MIN:
			robot_path.append(pose)
	else:
		robot_path.append(pose)


def main():
	# Init benchmarking node
	benchmark = BmBox()
	rospy.loginfo("FBM3W benchmarking node started")
	
	global tf_listener
	global tf_broadcaster
	tf_listener = tf.TransformListener()
	tf_broadcaster = tf.TransformBroadcaster()
	
	robot_path_publisher = rospy.Publisher('/fbm3w/robot_path_in_frame', Path, queue_size=10)
	target_path_publisher = rospy.Publisher('/fbm3w/target_path_in_frame', Path, queue_size=10)

	# Get params (list of line/spline for each run)
	runs_specifications = rospy.get_param('runs_specifications')
	
	# Variables to compute score
	current_run = 0
	best_run = None
	best_distance_error = None
	execution_time = 0.0
	runs_details = {}

	# Wait for client
	benchmark.WaitClient()
	
	# Start the benchmark
	while benchmark.Running() and current_run < BENCHMARK_RUNS:
		runs_details[current_run] = {}
		
		spec = runs_specifications[current_run]
		if spec == 'line':
			target_path = line_path
		if spec == 'spline':
			target_path = spline_path
		
		runs_details[current_run]['spec'] = spec
		rospy.loginfo("run spec: %s", spec)
		
		
		# Robot positions in reference position, in its frame (robot_frame)
		benchmark.ManualOperation()
		
		acquire_reference_position()
		
		if not benchmark.Running(): break;
		
		
		# Robot positions in starting position, in its frame (robot_frame)
		# with CFH, SendGoal doesn't return immediatly, but when the robot reaches starting_position
		# when SendGoal returns is also when the robot start to follow the path
		benchmark.SendGoal("start path following")
		
		### for test: if you want to simulate SendGoal that doesn't return immediately ###
	#	raw_input("STARTING POSITION\npress ENTER")
	#	time.sleep(0.01)
		
		# start collecting the robot's poses in robot_path, see mocap_callback()
		start_time = time.time()
		start_collecting_robot_path()
		
		# WaitResult returns when the robot finishes the path following
		benchmark.WaitResult()
		
		# stop collecting the robot's poses in robot_path (unsubscribe)
		end_time = time.time()
		end_collecting_robot_path()
		
		
		if benchmark.Timeout():
			print "TIMEOUT"
		#	execution_time = execution_time + (end_time - start_time)
		#	continue

		if not benchmark.Running():
			print "NOT RUNNING"
			continue
		
		
		# Evaluate execution time
		execution_time = execution_time + (end_time - start_time)

		rospy.loginfo("Execution time of run %i: %f" % (current_run, execution_time))
		runs_details[current_run]['execution_time'] = end_time - start_time
		
		# Compute accuracy (see documentation on how and why)
		global robot_path, robot_starting_position, robot_reference_position
		
		# the starting position for each run is extracted from the first pose in robot_path
		acquire_starting_position_from_path()
		# robot_frame is computed from reference_position (on negative x axis) and starting_position (in the origin)
		update_robot_frame()
		
		# only needed to visualise with rviz	
	#	broadcast_pose2D(translate_robot_pose(robot_starting_position), rospy.Time.now(), "my_robot_starting_position", "/world")
	#	broadcast_pose2D(translate_robot_pose(robot_reference_position), rospy.Time.now(), "my_robot_reference_position", "/world")
		
		# instantiate the robot and target paths, for logging reasons
		robot_path_in_frame = Path()
		robot_path_in_frame.header.frame_id = 'robot_frame'
		robot_path_in_frame.poses = [pose2D_to_pose(translate_robot_pose(robot_starting_position))]
		
		target_path_in_frame = Path()
		target_path_in_frame.header.frame_id = 'robot_frame'
		target_path_in_frame.poses = [pose2D_to_pose(target_path(0.0))]
		
		l = 0.0
		error_sum = 0.0
		N = len(robot_path)
		
		# compute total robot_path length
		L = 0.0
		for i in range(1, N): L = L + d(robot_path[i-1], robot_path[i])
		
		# compute avarage distance between robot_path and target_path
		for i in range(1, N):
			# translation from frame '/world' to frame '/robot_frame'
			robot_in_frame_pose = translate_robot_pose(robot_path[i])
			
			l = l + d(robot_path[i-1], robot_path[i])
			error_sum = error_sum + d(robot_in_frame_pose, target_path(l/L))
			
			robot_path_in_frame.poses.append(pose2D_to_pose(robot_in_frame_pose))
			target_path_in_frame.poses.append(pose2D_to_pose(target_path(l/L)))
		
		# publish robot_path and target_path as nav_msgs/path
		robot_path_publisher.publish(robot_path_in_frame)
		target_path_publisher.publish(target_path_in_frame)
		
		# (avarage)
		distance_error = error_sum / N
		
		rospy.loginfo("Distance error of run %i: %f" % (current_run, distance_error))
		runs_details[current_run]['distance_error'] = distance_error
		
		# select the best run in terms of accuracy
		if best_run == None or distance_error < best_distance_error:
			best_run = current_run
			best_distance_error = distance_error
		
		current_run = current_run + 1
	
	
	# Evaluate final score
	score = {
		'best_distance_error': best_distance_error,
		'best_run': best_run,
		'execution_time': execution_time,
		'runs_details': runs_details
	}
	
	score_yaml = yaml.dump(score)
	benchmark.SendScore(score_yaml)
	
	# Benchmark concluded
	benchmark.End()

	print score_yaml
	raw_input("press ENTER to close")
				
if __name__ == '__main__':
	main()
	
