#!/usr/bin/env python
import math
from math import sqrt, sin, cos, pi, atan2
import random
import time
import yaml

# ROS imports
import rospy
import tf
from rockin_scoring.BmBox import BmBox
from geometry_msgs.msg import Pose2D

# Benchmark runs
BENCHMARK_RUNS = 5

# c times mean distance measurement error
D_MIN = 0.00033 # reasonable with a smoothing value of 15

# robot path
robot_path = []



# target paths
def line_path(l):
	l = float(l)
	return Pose2D(0.30*l, 0.10*l, 0) # line from (0, 0) to (30, 10) [cm]

def parabola_path(l):
	l = float(l)
	return Pose2D(l**2/12, l, 0)
def semi_ellipse(l):
	l = float(l)
	return Pose2D(0.050 - 0.050*cos(pi*l), 0.048*sin(pi*l), 0) # semi ellipse (0,0),(5, 4.8), (10, 0) [cm]

spline_path = semi_ellipse

tf_listener = None
tf_broadcaster = None

# Euclidean distance between Pose2D (p1, p2)
def d(p1, p2):
	return sqrt( (p1.x-p2.x)**2 + (p1.y-p2.y)**2 )

# Look for the robot from GT system
def acquire_robot_position():
	global tf_listener
	
	while True:
		try:
			((x, y, _), q) = tf_listener.lookupTransform("/world", "/robot_at_work", rospy.Time(0))
			(_, _, theta) = tf.transformations.euler_from_quaternion(q)
			
			return Pose2D(x, y, theta)
			
		except (tf.LookupException, tf.ConnectivityException, tf.ExtrapolationException):
			rospy.loginfo("Position couldn't be acquired, retrying...")
			tf_listener.waitForTransform("/world", "/robot_at_work", rospy.Time(), rospy.Duration(2.0))

# given a robot Pose2D relative to world, returns a Pose2D relative to robot_frame
def translate_robot_pose(robot_pose2D):
	global tf_listener, tf_broadcaster, robot_starting_position, ref_to_start_quaternion
	while True:
		try:
			now = rospy.Time.now()
			
			# broadcast robot_frame
			tf_broadcaster.sendTransform((robot_starting_position.x, robot_starting_position.y, 0), ref_to_start_quaternion, now, "/robot_frame", "/world")
			
			# broadcast robot position and lookup robot position in robot_frame
			tf_broadcaster.sendTransform( (robot_pose2D.x, robot_pose2D.y, 0.0), (0,0,0,1), now, "/robot_in_frame", "/world")
			
			tf_listener.waitForTransform("/robot_frame", "/robot_in_frame", now, rospy.Duration(2.0) )
			((x, y, _), _) = tf_listener.lookupTransform("/robot_frame", "/robot_in_frame", now) # to obtain robot wrt path
			
			return Pose2D(x, y, 0)
		
		except (tf.LookupException, tf.ConnectivityException, tf.ExtrapolationException):
			rospy.loginfo("Transform couldn't be computed, retrying...")
			# return None

def broadcast_pose2D(pose2D, timestamp, child, parent):
	tf_broadcaster.sendTransform( (pose2D.x, pose2D.y, 0.0), (0,0,0,1), timestamp, child, parent)




#############################
#### benchmark functions ####
#############################

### Acquire reference_position
def acquire_reference_position():
	global robot_reference_position
	
	robot_reference_position = acquire_robot_position()
	rospy.loginfo("Acquired reference_position\n%s", robot_reference_position)

### Acquire starting_position
def acquire_starting_position():
	global robot_starting_position
	
	robot_starting_position = acquire_robot_position()
	rospy.loginfo("Acquired starting_position\n%s", robot_starting_position)

### Acquire starting_position from robot_path (the first position in robot's path
def acquire_starting_position_from_path():
	global robot_starting_position, robot_path
	
	print robot_path
	robot_starting_position = robot_path[0]
	rospy.loginfo("Acquired starting_position from robot_path\n%s", robot_starting_position)

### Updates ref_to_start_quaternion, so that robot_frame will be rotated as robot_starting_position - robot_reference_position
def update_robot_frame():
	global robot_reference_position, robot_starting_position, ref_to_start_quaternion
	
	ref_to_start_vector = (robot_starting_position.y - robot_reference_position.y, robot_starting_position.x - robot_reference_position.x)
	ref_to_start_quaternion = tf.transformations.quaternion_from_euler(0, 0, atan2(*ref_to_start_vector))
	
	print "robot_frame theta: ", atan2(*ref_to_start_vector)/pi*180


### Start collecting robot positions
def start_collecting_robot_path():
	global robot_path, mocap_subscriber
	
	robot_path = []
	mocap_subscriber = rospy.Subscriber("/fbm3w/robot_at_work/pose2d", Pose2D, mocap_callback)
	rospy.loginfo('Subscribed to "/fbm3w/robot_at_work/pose2d"')

### End collecting robot positions
def end_collecting_robot_path():
	global mocap_subscriber
	
	mocap_subscriber.unregister()
	rospy.loginfo('UNsubscribed from "/fbm3w/robot_at_work/pose2d"')

# note: untracked path is ignored and will be evaluated as a step
def mocap_callback(pose):
	global robot_path
	
	if len(robot_path)>0:
		if d(robot_path[-1], pose) >= D_MIN:
			robot_path.append(pose)
	else:
		robot_path.append(pose)


def main():
	
	# Init benchmarking node
	benchmark = BmBox()
	rospy.loginfo("FBM3W benchmarking node started")
	
	
	# init tf
	global tf_listener
	global tf_broadcaster
	tf_listener = tf.TransformListener()
	tf_broadcaster = tf.TransformBroadcaster()

	# Get items
	runs_specifications = rospy.get_param('runs_specifications')
	
	# Variables to compute score
	current_run = 0
	best_run = None
	best_distance_error = None
	execution_time = 0.0
	runs_details = {}

	# Wait for client
	benchmark.WaitClient()
	
	# Start the benchmark
	while benchmark.Running() and current_run < BENCHMARK_RUNS:
		runs_details[current_run] = {}
		
		spec = runs_specifications[current_run]
		if spec == 'line':
			target_path = line_path
		if spec == 'spline':
			target_path = spline_path
		
		runs_details[current_run]['spec'] = spec
		rospy.loginfo("run spec: %s", spec)
		
		
		# Robot positions in start position
		benchmark.ManualOperation()
		
		acquire_reference_position()
		
		if not benchmark.Running(): break;
		
		
		# Robot starts path following as goal
		benchmark.SendGoal("start path following")
		
		### test ###
		raw_input("STARTING POSITION\npress ENTER")
	#	time.sleep(0.01)
		
		start_time = time.time()
		start_collecting_robot_path()
		
		# Robot ends path following
		benchmark.WaitResult()
		
		end_time = time.time()
		end_collecting_robot_path()
		
		
		if benchmark.Timeout():
			print "TIMEOUT"
			execution_time = execution_time + (end_time - start_time)
			continue

		if not benchmark.Running():
			print "NOT RUNNING"
			continue
		
		
		# Evaluate execution time
		execution_time = execution_time + (end_time - start_time)

		rospy.loginfo("Execution time of run %i: %f" % (current_run, execution_time))
		runs_details[current_run]['execution_time'] = end_time - start_time
		
		# Compute accuracy
		global robot_path, robot_starting_position, robot_reference_position
		
		acquire_starting_position_from_path()
		update_robot_frame()
		
		broadcast_pose2D(translate_robot_pose(robot_starting_position), rospy.Time.now(), "my_robot_starting_position", "/world")
		broadcast_pose2D(translate_robot_pose(robot_reference_position), rospy.Time.now(), "my_robot_reference_position", "/world")
		
		l = 0.0
		error_sum = 0.0
		N = len(robot_path)
		
		# compute total robot_path length
		L = 0.0
		for i in range(1, N): L = L + d(robot_path[i-1], robot_path[i])
		
		for i in range(1, N):
			robot_in_frame_pose = translate_robot_pose(robot_path[i])
			
			l = l + d(robot_path[i-1], robot_path[i])
			error_sum = error_sum + d(robot_in_frame_pose, target_path(l/L))
			
			print "l/L:%1.4f\t%1.2f"%(l/L, 1000*d(robot_in_frame_pose, target_path(l/L)))
			
			broadcast_pose2D(robot_in_frame_pose, rospy.Time.now(), "my_robot_in_frame"+str(i), "/world")
			broadcast_pose2D(target_path(l/L), rospy.Time.now(), "my_target_path"+str(i), "/world")
		
		distance_error = error_sum / N
		
		rospy.loginfo("Distance error of run %i: %f" % (current_run, distance_error))
		runs_details[current_run]['distance_error'] = distance_error
		
		if best_run == None or distance_error < best_distance_error:
			best_run = current_run
			best_distance_error = distance_error
		
		current_run = current_run + 1
	
	
	# Evaluate final score
	score = {
		'best_distance_error': best_distance_error,
		'best_run': best_run,
		'execution_time': execution_time,
		'runs_details': runs_details
	}
	
	score_yaml = yaml.dump(score)
	benchmark.SendScore(score_yaml)
	
	# Benchmark concluded
	benchmark.End()

	print score_yaml
	raw_input("press ENTER to close")
				
if __name__ == '__main__':
	main()
	
